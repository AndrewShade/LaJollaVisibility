{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc7c966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ae52c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OceanDataGenerator:\n",
    "    def __init__(self):\n",
    "        self.buoy_id = \"201\" # SCRIPPS NEARSHORE, CA\n",
    "        self.buoy_features = [\n",
    "            'waveHs', 'waveTp', 'waveTa', 'waveDp', \n",
    "            'wavePeakPSD', 'sstSeaSurfaceTemperature'\n",
    "        ]\n",
    "        self.noaa_wind_station = \"9410230\" # Scripps Pier\n",
    "        self.owm_api_key = \"21bf8f260bb281800b97a8b5bc71ef51\"\n",
    "        self.lat, self.lon = 32.8328, -117.2713\n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        \n",
    "        # Classification Config\n",
    "        self.viz_bins = [0, 10, 15, 25, 200]\n",
    "        self.viz_labels = [0, 1, 2, 3] # 0: Poor, 1: Fair, 2: Good, 3: Excellent\n",
    "\n",
    "    def _apply_circular_transform(self, df, column):\n",
    "        rads = np.deg2rad(df[column])\n",
    "        df[f'{column}_sine'] = np.sin(rads)\n",
    "        df[f'{column}_cos'] = np.cos(rads)\n",
    "        return df\n",
    "\n",
    "    def fetch_buoy_data(self, days=650):\n",
    "        \"\"\"Fetches CDIP Archive & Realtime using pandas timing for stability.\"\"\"\n",
    "        base_url = \"http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip\"\n",
    "        urls = [\n",
    "            f\"{base_url}/archive/{self.buoy_id}p1/{self.buoy_id}p1_historic.nc\",\n",
    "            f\"{base_url}/realtime/{self.buoy_id}p1_rt.nc\"\n",
    "        ]\n",
    "        \n",
    "        # Using pd.Timestamp.now() avoids the 'datetime' attribute errors\n",
    "        start_date = (pd.Timestamp.now() - pd.Timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "        all_wave_aggs, all_sst_aggs = [], []\n",
    "\n",
    "        for url in urls:\n",
    "            try:\n",
    "                ds = xr.open_dataset(url, engine='pydap')\n",
    "                ds_subset = ds[self.buoy_features].sel(waveTime=slice(start_date, None))\n",
    "                \n",
    "                df_wave = ds_subset.drop_dims('sstTime').to_dataframe()\n",
    "                df_wave = self._apply_circular_transform(df_wave, 'waveDp')\n",
    "                \n",
    "                # Add Steepness and Energy pre-aggregation\n",
    "                df_wave['wave_steepness'] = df_wave['waveHs'] / df_wave['waveTp']\n",
    "                df_wave['swell_energy'] = (df_wave['waveHs']**2) * df_wave['waveTp']\n",
    "                \n",
    "                wave_agg = df_wave.resample('D').agg({\n",
    "                    'waveHs': ['max', 'mean'], \n",
    "                    'waveTp': 'mean',\n",
    "                    'wave_steepness': 'mean', # New feature\n",
    "                    'swell_energy': 'mean',   # New feature\n",
    "                    'waveDp_sine': 'mean', \n",
    "                    'waveDp_cos': 'mean', \n",
    "                    'wavePeakPSD': 'max'\n",
    "                })\n",
    "                wave_agg.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in wave_agg.columns.values]\n",
    "                all_wave_aggs.append(wave_agg)\n",
    "\n",
    "                try:\n",
    "                    df_sst = ds_subset.drop_dims('waveTime').to_dataframe()\n",
    "                    all_sst_aggs.append(df_sst.resample('D').agg({'sstSeaSurfaceTemperature': 'mean'}))\n",
    "                except: pass\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {url}: {e}\")\n",
    "\n",
    "        final_wave = pd.concat(all_wave_aggs).sort_index()\n",
    "        final_wave = final_wave[~final_wave.index.duplicated(keep='last')]\n",
    "        final_sst = pd.concat(all_sst_aggs).sort_index()\n",
    "        final_sst = final_sst[~final_sst.index.duplicated(keep='last')]\n",
    "\n",
    "        return final_wave.join(final_sst, how='inner')\n",
    "\n",
    "    def fetch_wind_data(self, days=650):\n",
    "        \"\"\"Wind fetcher with fixed pd.Timedelta logic.\"\"\"\n",
    "        end_date = pd.Timestamp.now().normalize()\n",
    "        start_date = end_date - pd.Timedelta(days=days)\n",
    "        all_chunks, curr = [], start_date\n",
    "        \n",
    "        while curr < end_date:\n",
    "            curr_end = min(curr + pd.Timedelta(days=30), end_date)\n",
    "            url = (f\"https://api.tidesandcurrents.noaa.gov/api/prod/datagetter?\"\n",
    "                   f\"begin_date={curr.strftime('%Y%m%d')}&end_date={curr_end.strftime('%Y%m%d')}&\"\n",
    "                   f\"station={self.noaa_wind_station}&product=wind&units=metric&time_zone=lst_ldt&format=json\")\n",
    "            try:\n",
    "                res = requests.get(url, headers=self.headers, timeout=15).json()\n",
    "                if 'data' in res: all_chunks.append(pd.DataFrame(res['data']))\n",
    "            except: pass\n",
    "            curr = curr_end + pd.Timedelta(minutes=6)\n",
    "\n",
    "        if not all_chunks: return pd.DataFrame()\n",
    "        df = pd.concat(all_chunks).drop_duplicates('t')\n",
    "        df['t'] = pd.to_datetime(df['t'])\n",
    "        df.set_index('t', inplace=True)\n",
    "        for col in ['s', 'g', 'd']: df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        df['wind_x'], df['wind_y'] = np.cos(np.radians(df['d'])), np.sin(np.radians(df['d']))\n",
    "        daily = df.resample('D').agg({'s': 'mean', 'g': 'max', 'wind_x': 'mean', 'wind_y': 'mean'}).rename(columns={'s': 'wind_speed', 'g': 'wind_gust'})\n",
    "        daily['wind_dir_mean'] = np.degrees(np.arctan2(daily['wind_y'], daily['wind_x'])) % 360\n",
    "        return daily.drop(columns=['wind_x', 'wind_y'])\n",
    "    \n",
    "    def fetch_tide_data(self, days=650):\n",
    "        \"\"\"Fetches daily tidal max and delta (flux) from NOAA.\"\"\"\n",
    "        end_date = pd.Timestamp.now().normalize()\n",
    "        start_date = end_date - pd.Timedelta(days=days)\n",
    "        all_chunks, curr = [], start_date\n",
    "        \n",
    "        while curr < end_date:\n",
    "            curr_end = min(curr + pd.Timedelta(days=30), end_date)\n",
    "            url = (f\"https://api.tidesandcurrents.noaa.gov/api/prod/datagetter?\"\n",
    "                   f\"begin_date={curr.strftime('%Y%m%d')}&end_date={curr_end.strftime('%Y%m%d')}&\"\n",
    "                   f\"station={self.noaa_wind_station}&product=water_level&datum=mllw&units=metric&time_zone=lst_ldt&format=json\")\n",
    "            try:\n",
    "                res = requests.get(url, headers=self.headers, timeout=15).json()\n",
    "                if 'data' in res: all_chunks.append(pd.DataFrame(res['data']))\n",
    "            except: pass\n",
    "            curr = curr_end + pd.Timedelta(minutes=6)\n",
    "\n",
    "        if not all_chunks: return pd.DataFrame()\n",
    "        df = pd.concat(all_chunks)\n",
    "        df['t'] = pd.to_datetime(df['t'])\n",
    "        df.set_index('t', inplace=True)\n",
    "        df['v'] = pd.to_numeric(df['v'], errors='coerce')\n",
    "        \n",
    "        # Calculate daily max height and the max hourly 'flux' (tide speed)\n",
    "        daily = df.resample('D').agg({'v': ['max', 'mean']})\n",
    "        daily.columns = ['tide_max', 'tide_mean']\n",
    "        return daily\n",
    "\n",
    "    def fetch_rain_data(self, days=365):\n",
    "        \"\"\"Rain fetcher using pandas timing objects.\"\"\"\n",
    "        rain_data = []\n",
    "        end_date = pd.Timestamp.now().normalize()\n",
    "        curr = end_date - pd.Timedelta(days=days)\n",
    "        \n",
    "        while curr <= end_date:\n",
    "            url = f\"https://api.openweathermap.org/data/3.0/onecall/day_summary?lat={self.lat}&lon={self.lon}&date={curr.strftime('%Y-%m-%d')}&appid={self.owm_api_key}&units=metric\"\n",
    "            try:\n",
    "                r = requests.get(url).json()\n",
    "                rain_data.append({'time': curr, 'rain_mm': r.get('precipitation', {}).get('total', 0)})\n",
    "            except: pass\n",
    "            curr += pd.Timedelta(days=1)\n",
    "        \n",
    "        df = pd.DataFrame(rain_data).set_index('time')\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df['rain_72h_weighted_mm'] = (df['rain_mm'] + (df['rain_mm'].shift(1) * 0.6) + (df['rain_mm'].shift(2) * 0.3)).fillna(0)\n",
    "        return df\n",
    "\n",
    "    def scrape_visibility_labels(self, total_pages=27):\n",
    "        base_url = \"https://justgetwet.com/blogs/dive-reports-and-conditions?page=\"\n",
    "        all_reports = []\n",
    "        for page_num in range(1, total_pages + 1):\n",
    "            try:\n",
    "                res = requests.get(f\"{base_url}{page_num}\", headers=self.headers, timeout=10)\n",
    "                soup = BeautifulSoup(res.text, 'html.parser')\n",
    "                for art in soup.find_all('div', class_='article__grid-meta'):\n",
    "                    date_tag, excerpt = art.find('time'), art.find('div', class_='article__excerpt')\n",
    "                    if not date_tag or not excerpt: continue\n",
    "                    viz_raw = re.search(r'(?:Viz|Vis|Visibility):\\s*([\\d\\-\\+m\\s\\']+)', excerpt.get_text(), re.IGNORECASE)\n",
    "                    if viz_raw:\n",
    "                        nums = re.findall(r'(\\d+)', viz_raw.group(1).lower())\n",
    "                        if not nums: continue\n",
    "                        viz_ft = float(nums[0])\n",
    "                        if 'm' in viz_raw.group(1).lower(): viz_ft *= 3.28\n",
    "                        all_reports.append({'date': pd.to_datetime(date_tag.get_text().strip()), 'visibility_ft': viz_ft})\n",
    "                time.sleep(0.5)\n",
    "            except: pass\n",
    "        df = pd.DataFrame(all_reports).drop_duplicates('date')\n",
    "        df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
    "        return df.set_index('date').sort_index()\n",
    "\n",
    "    def run(self, days=650, scrape_pages=27):\n",
    "        \"\"\"Unified run with normalization, lags 1-3, and trend.\"\"\"\n",
    "        df_buoy = self.fetch_buoy_data(days=days)\n",
    "        df_wind = self.fetch_wind_data(days=days)\n",
    "        df_rain = self.fetch_rain_data(days=days)\n",
    "        df_tide = self.fetch_tide_data(days=days) # New fetcher\n",
    "        df_labels = self.scrape_visibility_labels(total_pages=scrape_pages)\n",
    "\n",
    "        for d in [df_buoy, df_wind, df_rain,df_tide, df_labels]:\n",
    "            if not d.empty:\n",
    "                d.index = pd.to_datetime(d.index).normalize().tz_localize(None)\n",
    "\n",
    "        #Saving intermediate states to class variables\n",
    "        self.df_buoy = df_buoy.copy() \n",
    "        self.df_wind = df_wind.copy()\n",
    "        self.df_rain = df_rain.copy()\n",
    "        self.df_tide = df_tide.copy()\n",
    "        self.df_labels = df_labels.copy()\n",
    "        audit_dict = {'df_buoy':self.df_buoy,\n",
    "                      'df_wind':self.df_wind,\n",
    "                      'df_rain':self.df_rain,\n",
    "                      'df_labels':self.df_labels,\n",
    "                      'df_tide':self.df_tide\n",
    "                      }\n",
    "        for k,v in audit_dict.items():\n",
    "            print(f\"{k} min: {v.index.min()} {k} max: {v.index.max()}\")\n",
    "        # 2. Add SST and Tide Change Features\n",
    "        if 'sstSeaSurfaceTemperature' in df_buoy.columns:\n",
    "            df_buoy['sst_diff_24h'] = df_buoy['sstSeaSurfaceTemperature'].diff(1)\n",
    "            df_buoy['sst_diff_48h'] = df_buoy['sstSeaSurfaceTemperature'].diff(2)\n",
    "\n",
    "        # 3. Join the new tide data\n",
    "        final_df = df_buoy.join(df_wind, how='inner').join(df_rain, how='inner')\\\n",
    "                          .join(df_tide, how='inner').join(df_labels, how='inner')\n",
    "\n",
    "\n",
    "        # Seasonality\n",
    "        day_of_year = pd.to_datetime(final_df.index).dayofyear\n",
    "        final_df['season_sine'] = np.sin(2 * np.pi * day_of_year / 365.25)\n",
    "        final_df['season_cos'] = np.cos(2 * np.pi * day_of_year / 365.25)\n",
    "\n",
    "        # Lags 1-3\n",
    "        cols_to_lag = ['waveHs_mean', 'waveHs_max', 'wind_speed', 'wavePeakPSD_max', 'rain_72h_weighted_mm']\n",
    "        for col in cols_to_lag:\n",
    "            if col in final_df.columns:\n",
    "                final_df[f'{col}_lag1'] = final_df[col].shift(1)\n",
    "                final_df[f'{col}_lag2'] = final_df[col].shift(2)\n",
    "                final_df[f'{col}_lag3'] = final_df[col].shift(3)\n",
    "\n",
    "        # Swell Trend\n",
    "        if 'waveHs_mean' in final_df.columns:\n",
    "            final_df['swell_trend_3d'] = final_df['waveHs_mean'].diff(periods=3)\n",
    "        print(f\"final_df Pre NA Drop {final_df.shape} Post NA Drop: {final_df.dropna().shape}\")\n",
    "        self.data = final_df.dropna()\n",
    "        return self.data\n",
    "\n",
    "    def save_data(self, df, path=\"training_data.parquet\", as_classification=False):\n",
    "        export_df = df.copy()\n",
    "        if as_classification:\n",
    "            export_df['target'] = pd.cut(export_df['visibility_ft'], bins=self.viz_bins, labels=self.viz_labels,include_lowest=True).astype(int)\n",
    "            export_df.drop(columns=['visibility_ft'], inplace=True)\n",
    "        else:\n",
    "            export_df.rename(columns={'visibility_ft': 'target'}, inplace=True)\n",
    "        export_df.to_parquet(path, engine=\"fastparquet\")\n",
    "        print(f\"Success. Parquet saved to {path} with {len(export_df)} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3523c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew Shade\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydap\\handlers\\dap.py:143: UserWarning: PyDAP was unable to determine the DAP protocol defaulting to DAP2. DAP2 is consider legacy and may result in slower responses. \n",
      "Consider replacing `http` in your `url` with either `dap2` or `dap4` to specify the DAP protocol (e.g. `dap2://<data_url>` or `dap4://<data_url>`).  For more \n",
      "information, go to https://www.opendap.org/faq-page.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Andrew Shade\\AppData\\Roaming\\Python\\Python312\\site-packages\\pydap\\handlers\\dap.py:143: UserWarning: PyDAP was unable to determine the DAP protocol defaulting to DAP2. DAP2 is consider legacy and may result in slower responses. \n",
      "Consider replacing `http` in your `url` with either `dap2` or `dap4` to specify the DAP protocol (e.g. `dap2://<data_url>` or `dap4://<data_url>`).  For more \n",
      "information, go to https://www.opendap.org/faq-page.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_buoy min: 2024-03-16 00:00:00 df_buoy max: 2026-02-12 00:00:00\n",
      "df_wind min: 2024-03-16 00:00:00 df_wind max: 2026-02-11 00:00:00\n",
      "df_rain min: 2024-03-16 00:00:00 df_rain max: 2026-02-11 00:00:00\n",
      "df_labels min: 2024-03-16 00:00:00 df_labels max: 2026-02-10 00:00:00\n",
      "df_tide min: 2024-03-16 00:00:00 df_tide max: 2026-02-11 00:00:00\n",
      "final_df Pre NA Drop (522, 37) Post NA Drop: (519, 37)\n"
     ]
    }
   ],
   "source": [
    "gen = OceanDataGenerator()\n",
    "df = gen.run(697,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0958c4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waveHs_max</th>\n",
       "      <th>waveHs_mean</th>\n",
       "      <th>waveTp_mean</th>\n",
       "      <th>wave_steepness_mean</th>\n",
       "      <th>swell_energy_mean</th>\n",
       "      <th>waveDp_sine_mean</th>\n",
       "      <th>waveDp_cos_mean</th>\n",
       "      <th>wavePeakPSD_max</th>\n",
       "      <th>sstSeaSurfaceTemperature</th>\n",
       "      <th>sst_diff_24h</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed_lag1</th>\n",
       "      <th>wind_speed_lag2</th>\n",
       "      <th>wind_speed_lag3</th>\n",
       "      <th>wavePeakPSD_max_lag1</th>\n",
       "      <th>wavePeakPSD_max_lag2</th>\n",
       "      <th>wavePeakPSD_max_lag3</th>\n",
       "      <th>rain_72h_weighted_mm_lag1</th>\n",
       "      <th>rain_72h_weighted_mm_lag2</th>\n",
       "      <th>rain_72h_weighted_mm_lag3</th>\n",
       "      <th>swell_trend_3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-22</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.475833</td>\n",
       "      <td>15.583219</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>3.560712</td>\n",
       "      <td>-0.955971</td>\n",
       "      <td>0.281128</td>\n",
       "      <td>0.581115</td>\n",
       "      <td>17.285418</td>\n",
       "      <td>0.309376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.711250</td>\n",
       "      <td>1.417500</td>\n",
       "      <td>3.240417</td>\n",
       "      <td>0.487821</td>\n",
       "      <td>1.118729</td>\n",
       "      <td>0.757443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.143125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-23</th>\n",
       "      <td>1.40</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>14.369962</td>\n",
       "      <td>0.051740</td>\n",
       "      <td>4.340137</td>\n",
       "      <td>-0.934940</td>\n",
       "      <td>0.338181</td>\n",
       "      <td>1.611545</td>\n",
       "      <td>17.132292</td>\n",
       "      <td>-0.153126</td>\n",
       "      <td>...</td>\n",
       "      <td>1.699583</td>\n",
       "      <td>1.711250</td>\n",
       "      <td>1.417500</td>\n",
       "      <td>0.581115</td>\n",
       "      <td>0.487821</td>\n",
       "      <td>1.118729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.047292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-25</th>\n",
       "      <td>2.74</td>\n",
       "      <td>1.969375</td>\n",
       "      <td>8.158076</td>\n",
       "      <td>0.245759</td>\n",
       "      <td>32.531830</td>\n",
       "      <td>-0.969695</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>8.518099</td>\n",
       "      <td>15.966667</td>\n",
       "      <td>-0.191666</td>\n",
       "      <td>...</td>\n",
       "      <td>5.215417</td>\n",
       "      <td>1.699583</td>\n",
       "      <td>1.711250</td>\n",
       "      <td>1.611545</td>\n",
       "      <td>0.581115</td>\n",
       "      <td>0.487821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.509167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.681667</td>\n",
       "      <td>13.435426</td>\n",
       "      <td>0.057479</td>\n",
       "      <td>6.186221</td>\n",
       "      <td>-0.906081</td>\n",
       "      <td>0.403287</td>\n",
       "      <td>0.746166</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.163333</td>\n",
       "      <td>5.215417</td>\n",
       "      <td>1.699583</td>\n",
       "      <td>8.518099</td>\n",
       "      <td>1.611545</td>\n",
       "      <td>0.581115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-29</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.780625</td>\n",
       "      <td>11.366722</td>\n",
       "      <td>0.085616</td>\n",
       "      <td>7.105659</td>\n",
       "      <td>-0.930865</td>\n",
       "      <td>0.342202</td>\n",
       "      <td>1.274041</td>\n",
       "      <td>15.382291</td>\n",
       "      <td>-0.367709</td>\n",
       "      <td>...</td>\n",
       "      <td>3.214167</td>\n",
       "      <td>4.163333</td>\n",
       "      <td>5.215417</td>\n",
       "      <td>0.746166</td>\n",
       "      <td>8.518099</td>\n",
       "      <td>1.611545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-05</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.464583</td>\n",
       "      <td>12.316020</td>\n",
       "      <td>0.038797</td>\n",
       "      <td>2.647382</td>\n",
       "      <td>-0.971789</td>\n",
       "      <td>0.221565</td>\n",
       "      <td>0.480558</td>\n",
       "      <td>17.266666</td>\n",
       "      <td>-0.146875</td>\n",
       "      <td>...</td>\n",
       "      <td>1.424583</td>\n",
       "      <td>1.037083</td>\n",
       "      <td>1.202083</td>\n",
       "      <td>1.326035</td>\n",
       "      <td>1.141329</td>\n",
       "      <td>1.807949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.258125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-06</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.568333</td>\n",
       "      <td>12.871403</td>\n",
       "      <td>0.044477</td>\n",
       "      <td>4.194223</td>\n",
       "      <td>-0.961240</td>\n",
       "      <td>0.265666</td>\n",
       "      <td>1.436477</td>\n",
       "      <td>17.360416</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257083</td>\n",
       "      <td>1.424583</td>\n",
       "      <td>1.037083</td>\n",
       "      <td>0.480558</td>\n",
       "      <td>1.326035</td>\n",
       "      <td>1.141329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-07</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.853750</td>\n",
       "      <td>13.965505</td>\n",
       "      <td>0.061576</td>\n",
       "      <td>10.318934</td>\n",
       "      <td>-0.944326</td>\n",
       "      <td>0.319713</td>\n",
       "      <td>2.333089</td>\n",
       "      <td>17.576042</td>\n",
       "      <td>0.215626</td>\n",
       "      <td>...</td>\n",
       "      <td>2.422500</td>\n",
       "      <td>2.257083</td>\n",
       "      <td>1.424583</td>\n",
       "      <td>1.436477</td>\n",
       "      <td>0.480558</td>\n",
       "      <td>1.326035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-08</th>\n",
       "      <td>1.03</td>\n",
       "      <td>0.863333</td>\n",
       "      <td>12.833111</td>\n",
       "      <td>0.067706</td>\n",
       "      <td>9.709422</td>\n",
       "      <td>-0.933765</td>\n",
       "      <td>0.347968</td>\n",
       "      <td>1.754516</td>\n",
       "      <td>17.660418</td>\n",
       "      <td>0.084375</td>\n",
       "      <td>...</td>\n",
       "      <td>2.288703</td>\n",
       "      <td>2.422500</td>\n",
       "      <td>2.257083</td>\n",
       "      <td>2.333089</td>\n",
       "      <td>1.436477</td>\n",
       "      <td>0.480558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-10</th>\n",
       "      <td>1.02</td>\n",
       "      <td>0.919167</td>\n",
       "      <td>12.204010</td>\n",
       "      <td>0.076245</td>\n",
       "      <td>10.324429</td>\n",
       "      <td>-0.928080</td>\n",
       "      <td>0.366483</td>\n",
       "      <td>2.018174</td>\n",
       "      <td>17.502083</td>\n",
       "      <td>-0.173960</td>\n",
       "      <td>...</td>\n",
       "      <td>1.481667</td>\n",
       "      <td>2.288703</td>\n",
       "      <td>2.422500</td>\n",
       "      <td>1.754516</td>\n",
       "      <td>2.333089</td>\n",
       "      <td>1.436477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            waveHs_max  waveHs_mean  waveTp_mean  wave_steepness_mean  \\\n",
       "2024-03-22        0.57     0.475833    15.583219             0.030705   \n",
       "2024-03-23        1.40     0.570000    14.369962             0.051740   \n",
       "2024-03-25        2.74     1.969375     8.158076             0.245759   \n",
       "2024-03-28        0.81     0.681667    13.435426             0.057479   \n",
       "2024-03-29        0.98     0.780625    11.366722             0.085616   \n",
       "...                ...          ...          ...                  ...   \n",
       "2026-02-05        0.54     0.464583    12.316020             0.038797   \n",
       "2026-02-06        0.78     0.568333    12.871403             0.044477   \n",
       "2026-02-07        0.98     0.853750    13.965505             0.061576   \n",
       "2026-02-08        1.03     0.863333    12.833111             0.067706   \n",
       "2026-02-10        1.02     0.919167    12.204010             0.076245   \n",
       "\n",
       "            swell_energy_mean  waveDp_sine_mean  waveDp_cos_mean  \\\n",
       "2024-03-22           3.560712         -0.955971         0.281128   \n",
       "2024-03-23           4.340137         -0.934940         0.338181   \n",
       "2024-03-25          32.531830         -0.969695         0.238400   \n",
       "2024-03-28           6.186221         -0.906081         0.403287   \n",
       "2024-03-29           7.105659         -0.930865         0.342202   \n",
       "...                       ...               ...              ...   \n",
       "2026-02-05           2.647382         -0.971789         0.221565   \n",
       "2026-02-06           4.194223         -0.961240         0.265666   \n",
       "2026-02-07          10.318934         -0.944326         0.319713   \n",
       "2026-02-08           9.709422         -0.933765         0.347968   \n",
       "2026-02-10          10.324429         -0.928080         0.366483   \n",
       "\n",
       "            wavePeakPSD_max  sstSeaSurfaceTemperature  sst_diff_24h  ...  \\\n",
       "2024-03-22         0.581115                 17.285418      0.309376  ...   \n",
       "2024-03-23         1.611545                 17.132292     -0.153126  ...   \n",
       "2024-03-25         8.518099                 15.966667     -0.191666  ...   \n",
       "2024-03-28         0.746166                 15.750000      0.206250  ...   \n",
       "2024-03-29         1.274041                 15.382291     -0.367709  ...   \n",
       "...                     ...                       ...           ...  ...   \n",
       "2026-02-05         0.480558                 17.266666     -0.146875  ...   \n",
       "2026-02-06         1.436477                 17.360416      0.093750  ...   \n",
       "2026-02-07         2.333089                 17.576042      0.215626  ...   \n",
       "2026-02-08         1.754516                 17.660418      0.084375  ...   \n",
       "2026-02-10         2.018174                 17.502083     -0.173960  ...   \n",
       "\n",
       "            wind_speed_lag1  wind_speed_lag2  wind_speed_lag3  \\\n",
       "2024-03-22         1.711250         1.417500         3.240417   \n",
       "2024-03-23         1.699583         1.711250         1.417500   \n",
       "2024-03-25         5.215417         1.699583         1.711250   \n",
       "2024-03-28         4.163333         5.215417         1.699583   \n",
       "2024-03-29         3.214167         4.163333         5.215417   \n",
       "...                     ...              ...              ...   \n",
       "2026-02-05         1.424583         1.037083         1.202083   \n",
       "2026-02-06         2.257083         1.424583         1.037083   \n",
       "2026-02-07         2.422500         2.257083         1.424583   \n",
       "2026-02-08         2.288703         2.422500         2.257083   \n",
       "2026-02-10         1.481667         2.288703         2.422500   \n",
       "\n",
       "            wavePeakPSD_max_lag1  wavePeakPSD_max_lag2  wavePeakPSD_max_lag3  \\\n",
       "2024-03-22              0.487821              1.118729              0.757443   \n",
       "2024-03-23              0.581115              0.487821              1.118729   \n",
       "2024-03-25              1.611545              0.581115              0.487821   \n",
       "2024-03-28              8.518099              1.611545              0.581115   \n",
       "2024-03-29              0.746166              8.518099              1.611545   \n",
       "...                          ...                   ...                   ...   \n",
       "2026-02-05              1.326035              1.141329              1.807949   \n",
       "2026-02-06              0.480558              1.326035              1.141329   \n",
       "2026-02-07              1.436477              0.480558              1.326035   \n",
       "2026-02-08              2.333089              1.436477              0.480558   \n",
       "2026-02-10              1.754516              2.333089              1.436477   \n",
       "\n",
       "            rain_72h_weighted_mm_lag1  rain_72h_weighted_mm_lag2  \\\n",
       "2024-03-22                        0.0                        0.0   \n",
       "2024-03-23                        0.0                        0.0   \n",
       "2024-03-25                        0.0                        0.0   \n",
       "2024-03-28                        0.0                        0.0   \n",
       "2024-03-29                        0.0                        0.0   \n",
       "...                               ...                        ...   \n",
       "2026-02-05                        0.0                        0.0   \n",
       "2026-02-06                        0.0                        0.0   \n",
       "2026-02-07                        0.0                        0.0   \n",
       "2026-02-08                        0.0                        0.0   \n",
       "2026-02-10                        0.0                        0.0   \n",
       "\n",
       "            rain_72h_weighted_mm_lag3  swell_trend_3d  \n",
       "2024-03-22                        0.0       -0.143125  \n",
       "2024-03-23                        0.0       -0.047292  \n",
       "2024-03-25                        0.0        1.509167  \n",
       "2024-03-28                        0.0        0.205833  \n",
       "2024-03-29                        0.0        0.210625  \n",
       "...                               ...             ...  \n",
       "2026-02-05                        0.0       -0.258125  \n",
       "2026-02-06                        0.0        0.024167  \n",
       "2026-02-07                        0.0        0.189167  \n",
       "2026-02-08                        0.0        0.398750  \n",
       "2026-02-10                        0.0        0.350833  \n",
       "\n",
       "[519 rows x 37 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04cafcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. Parquet saved to C:/Users\\Andrew Shade/Documents/Visibility Code/visibility_data_class_xl.parquet with 519 records.\n"
     ]
    }
   ],
   "source": [
    "gen.save_data(df,path=r\"C:/Users\\Andrew Shade/Documents/Visibility Code/visibility_data_class_xl.parquet\",as_classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ea2979d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. Parquet saved to C:/Users\\Andrew Shade/Documents/Visibility Code/visibility_data_reg_xl.parquet with 519 records.\n"
     ]
    }
   ],
   "source": [
    "gen.save_data(df,path=r\"C:/Users\\Andrew Shade/Documents/Visibility Code/visibility_data_reg_xl.parquet\",as_classification=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80828420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
